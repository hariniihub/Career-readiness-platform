{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idbX4-Klp9m8",
        "outputId": "bed0f5af-b9ad-44d0-83cd-70fea58e9ce9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CSV files created successfully!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Resume data\n",
        "resumes = [\n",
        "    {\"name\":\"Uma\",\"text\":\"Python, Machine Learning, TensorFlow, Data Analysis, SQL\"},\n",
        "    {\"name\":\"Anu\",\"text\":\"Java, Cloud Computing, DevOps, Kubernetes, AWS\"},\n",
        "    {\"name\":\"Ram\",\"text\":\"ReactJS, Node.js, HTML, CSS, UI/UX Design\"},\n",
        "    {\"name\":\"Sita\",\"text\":\"Python, Data Science, Pandas, Statistics, SQL\"},\n",
        "    {\"name\":\"Radha\",\"text\":\"Cybersecurity, Network Security, Ethical Hacking, Linux\"}\n",
        "]\n",
        "\n",
        "# Internship data\n",
        "internships = [\n",
        "    {\"title\":\"ML Engineer Intern\",\"text\":\"Python, Machine Learning, TensorFlow, Data Science\"},\n",
        "    {\"title\":\"Cloud Developer Intern\",\"text\":\"Cloud Computing, AWS, DevOps, Kubernetes\"},\n",
        "    {\"title\":\"Frontend Developer Intern\",\"text\":\"ReactJS, HTML, CSS, UI/UX Design\"},\n",
        "    {\"title\":\"Data Analyst Intern\",\"text\":\"Data Analysis, Python, SQL, Statistics, Pandas\"},\n",
        "    {\"title\":\"Cybersecurity Intern\",\"text\":\"Network Security, Ethical Hacking, Linux, Security Tools\"}\n",
        "]\n",
        "\n",
        "# Save CSVs\n",
        "pd.DataFrame(resumes).to_csv(\"resumes.csv\", index=False)\n",
        "pd.DataFrame(internships).to_csv(\"internships.csv\", index=False)\n",
        "\n",
        "print(\"CSV files created successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "LSD4xcVnrFFn",
        "outputId": "1f6bfbdf-9421-4a84-a7e7-76734e5b5537"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_11b62fd4-09ab-42a0-9572-6770c68ed05c\", \"resumes.csv\", 291)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_a3b0f9eb-1371-43c2-b3cd-46b25045093c\", \"internships.csv\", 359)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"resumes.csv\")\n",
        "files.download(\"internships.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qe6ZYNKrNEz",
        "outputId": "021a2589-2c04-478b-a9fb-6ed61b219169"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (0.9.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install sentence-transformers scikit-learn tabulate pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RV3s1eAVse5_",
        "outputId": "412c427f-ec15-419f-c10d-36101a53f6f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Resumes ===\n",
            "╒════════╤══════════════════════════════════════════════════════════╕\n",
            "│ name   │ text                                                     │\n",
            "╞════════╪══════════════════════════════════════════════════════════╡\n",
            "│ Uma    │ Python, Machine Learning, TensorFlow, Data Analysis, SQL │\n",
            "├────────┼──────────────────────────────────────────────────────────┤\n",
            "│ Anu    │ Java, Cloud Computing, DevOps, Kubernetes, AWS           │\n",
            "├────────┼──────────────────────────────────────────────────────────┤\n",
            "│ Ram    │ ReactJS, Node.js, HTML, CSS, UI/UX Design                │\n",
            "├────────┼──────────────────────────────────────────────────────────┤\n",
            "│ Sita   │ Python, Data Science, Pandas, Statistics, SQL            │\n",
            "├────────┼──────────────────────────────────────────────────────────┤\n",
            "│ Radha  │ Cybersecurity, Network Security, Ethical Hacking, Linux  │\n",
            "╘════════╧══════════════════════════════════════════════════════════╛\n",
            "\n",
            "=== Internships ===\n",
            "╒═══════════════════════════╤══════════════════════════════════════════════════════════╕\n",
            "│ title                     │ text                                                     │\n",
            "╞═══════════════════════════╪══════════════════════════════════════════════════════════╡\n",
            "│ ML Engineer Intern        │ Python, Machine Learning, TensorFlow, Data Science       │\n",
            "├───────────────────────────┼──────────────────────────────────────────────────────────┤\n",
            "│ Cloud Developer Intern    │ Cloud Computing, AWS, DevOps, Kubernetes                 │\n",
            "├───────────────────────────┼──────────────────────────────────────────────────────────┤\n",
            "│ Frontend Developer Intern │ ReactJS, HTML, CSS, UI/UX Design                         │\n",
            "├───────────────────────────┼──────────────────────────────────────────────────────────┤\n",
            "│ Data Analyst Intern       │ Data Analysis, Python, SQL, Statistics, Pandas           │\n",
            "├───────────────────────────┼──────────────────────────────────────────────────────────┤\n",
            "│ Cybersecurity Intern      │ Network Security, Ethical Hacking, Linux, Security Tools │\n",
            "╘═══════════════════════════╧══════════════════════════════════════════════════════════╛\n",
            "\n",
            "=== Top Internship Matches ===\n",
            "╒═══════════╤═══════════════════════════╤═══════════════════╕\n",
            "│ Student   │ Internship                │   Match Score (%) │\n",
            "╞═══════════╪═══════════════════════════╪═══════════════════╡\n",
            "│ Uma       │ ML Engineer Intern        │             86.95 │\n",
            "├───────────┼───────────────────────────┼───────────────────┤\n",
            "│ Uma       │ Data Analyst Intern       │             72.62 │\n",
            "├───────────┼───────────────────────────┼───────────────────┤\n",
            "│ Uma       │ Cloud Developer Intern    │             21.63 │\n",
            "├───────────┼───────────────────────────┼───────────────────┤\n",
            "│ Anu       │ Cloud Developer Intern    │             89.96 │\n",
            "├───────────┼───────────────────────────┼───────────────────┤\n",
            "│ Anu       │ ML Engineer Intern        │             30.97 │\n",
            "├───────────┼───────────────────────────┼───────────────────┤\n",
            "│ Anu       │ Cybersecurity Intern      │             24.49 │\n",
            "├───────────┼───────────────────────────┼───────────────────┤\n",
            "│ Ram       │ Frontend Developer Intern │             95.48 │\n",
            "├───────────┼───────────────────────────┼───────────────────┤\n",
            "│ Ram       │ Cloud Developer Intern    │             24.65 │\n",
            "├───────────┼───────────────────────────┼───────────────────┤\n",
            "│ Ram       │ ML Engineer Intern        │             23.06 │\n",
            "├───────────┼───────────────────────────┼───────────────────┤\n",
            "│ Sita      │ Data Analyst Intern       │             95.86 │\n",
            "├───────────┼───────────────────────────┼───────────────────┤\n",
            "│ Sita      │ ML Engineer Intern        │             61.79 │\n",
            "├───────────┼───────────────────────────┼───────────────────┤\n",
            "│ Sita      │ Frontend Developer Intern │             19.61 │\n",
            "├───────────┼───────────────────────────┼───────────────────┤\n",
            "│ Radha     │ Cybersecurity Intern      │             89.47 │\n",
            "├───────────┼───────────────────────────┼───────────────────┤\n",
            "│ Radha     │ Cloud Developer Intern    │             27.04 │\n",
            "├───────────┼───────────────────────────┼───────────────────┤\n",
            "│ Radha     │ ML Engineer Intern        │             25.54 │\n",
            "╘═══════════╧═══════════════════════════╧═══════════════════╛\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tabulate import tabulate\n",
        "\n",
        "\n",
        "# Load CSV Files\n",
        "resumes = pd.read_csv(\"resumes.csv\")\n",
        "internships = pd.read_csv(\"internships.csv\")\n",
        "\n",
        "# Display CSVs\n",
        "print(\"\\n=== Resumes ===\")\n",
        "print(tabulate(resumes, headers='keys', tablefmt='fancy_grid', showindex=False))\n",
        "\n",
        "print(\"\\n=== Internships ===\")\n",
        "print(tabulate(internships, headers='keys', tablefmt='fancy_grid', showindex=False))\n",
        "\n",
        "\n",
        "# Load Embedding Model (NO OUTPUT SHOWN)\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "\n",
        "# Convert Text to Embeddings\n",
        "resume_embeddings = model.encode(resumes['text'].tolist(), show_progress_bar=False)\n",
        "internship_embeddings = model.encode(internships['text'].tolist(), show_progress_bar=False)\n",
        "\n",
        "\n",
        "# Compute Cosine Similarity\n",
        "sim_matrix = cosine_similarity(resume_embeddings, internship_embeddings)\n",
        "\n",
        "\n",
        "# Generate Top Matches\n",
        "all_matches = []\n",
        "\n",
        "for i, r in resumes.iterrows():\n",
        "    sim_scores = sim_matrix[i]\n",
        "    top_idx = sim_scores.argsort()[::-1][:3]\n",
        "    for idx in top_idx:\n",
        "        all_matches.append({\n",
        "            \"Student\": r['name'],\n",
        "            \"Internship\": internships.loc[idx, 'title'],\n",
        "            \"Match Score (%)\": round(sim_scores[idx] * 100, 2)\n",
        "        })\n",
        "\n",
        "matches_df = pd.DataFrame(all_matches)\n",
        "\n",
        "# Display FINAL TABLE ONLY\n",
        "print(\"\\n=== Top Internship Matches ===\")\n",
        "print(tabulate(matches_df, headers='keys', tablefmt='fancy_grid', showindex=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRHBQOxqs9Rn",
        "outputId": "57722537-e461-49dc-d752-659aca5e2f0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Skill Gap Analysis ===\n",
            "╒═══════════╤═══════════════════════════╤══════════════════════════════════════════╤══════════════════╕\n",
            "│ Student   │ Best Internship           │ Matched Skills                           │ Missing Skills   │\n",
            "╞═══════════╪═══════════════════════════╪══════════════════════════════════════════╪══════════════════╡\n",
            "│ Uma       │ ML Engineer Intern        │ machine learning, python, tensorflow     │ data science     │\n",
            "├───────────┼───────────────────────────┼──────────────────────────────────────────┼──────────────────┤\n",
            "│ Anu       │ Cloud Developer Intern    │ aws, cloud computing, devops, kubernetes │ None             │\n",
            "├───────────┼───────────────────────────┼──────────────────────────────────────────┼──────────────────┤\n",
            "│ Ram       │ Frontend Developer Intern │ css, html, reactjs, ui/ux design         │ None             │\n",
            "├───────────┼───────────────────────────┼──────────────────────────────────────────┼──────────────────┤\n",
            "│ Sita      │ Data Analyst Intern       │ pandas, python, sql, statistics          │ data analysis    │\n",
            "├───────────┼───────────────────────────┼──────────────────────────────────────────┼──────────────────┤\n",
            "│ Radha     │ Cybersecurity Intern      │ ethical hacking, linux, network security │ security tools   │\n",
            "╘═══════════╧═══════════════════════════╧══════════════════════════════════════════╧══════════════════╛\n"
          ]
        }
      ],
      "source": [
        "# Skill Gap Analysis\n",
        "\n",
        "\n",
        "def extract_skills(text):\n",
        "    return set(skill.strip().lower() for skill in text.split(\",\"))\n",
        "\n",
        "skill_gap_results = []\n",
        "\n",
        "for i, r in resumes.iterrows():\n",
        "    resume_skills = extract_skills(r['text'])\n",
        "\n",
        "    # Best matched internship\n",
        "    best_idx = sim_matrix[i].argmax()\n",
        "    internship = internships.loc[best_idx]\n",
        "    internship_skills = extract_skills(internship['text'])\n",
        "\n",
        "    matched_skills = resume_skills.intersection(internship_skills)\n",
        "    missing_skills = internship_skills - resume_skills\n",
        "\n",
        "    skill_gap_results.append({\n",
        "        \"Student\": r['name'],\n",
        "        \"Best Internship\": internship['title'],\n",
        "        \"Matched Skills\": \", \".join(sorted(matched_skills)),\n",
        "        \"Missing Skills\": \", \".join(sorted(missing_skills)) if missing_skills else \"None\"\n",
        "    })\n",
        "\n",
        "skill_gap_df = pd.DataFrame(skill_gap_results)\n",
        "\n",
        "print(\"\\n=== Skill Gap Analysis ===\")\n",
        "print(tabulate(skill_gap_df, headers='keys', tablefmt='fancy_grid', showindex=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcHfsKRas9jD",
        "outputId": "17113958-5380-4bb4-bffb-5a642d79baf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CSV files saved successfully\n"
          ]
        }
      ],
      "source": [
        "# Save match results\n",
        "matches_df.to_csv(\"internship_match_results.csv\", index=False)\n",
        "\n",
        "# Save skill gap results\n",
        "skill_gap_df.to_csv(\"skill_gap_analysis.csv\", index=False)\n",
        "\n",
        "print(\"CSV files saved successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "0_NHqqbks93k",
        "outputId": "cd58d4a5-dde4-440d-c37d-aec66a803207"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_497b700a-9338-425c-9421-1a8326f562e3\", \"internship_match_results.csv\", 515)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_ee2f5e82-15bc-4f2a-8aec-975baa343e35\", \"skill_gap_analysis.csv\", 432)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"internship_match_results.csv\")\n",
        "files.download(\"skill_gap_analysis.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo-OQh6sMLqT",
        "outputId": "a7dcfbb5-38cb-4f94-85dd-18f7b8e35324"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.5.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Downloading pyngrok-7.5.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok\n",
        "from pyngrok import ngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rN9H3W05XsE"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"36yZ68qk5fWd9g7HLmVDsSVnAn6_sSf3bdFGf1oUAEYJ3jpd\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAzX0-Z5S6ag",
        "outputId": "41cac3f3-c653-42ba-c533-03579ab57002"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngrok version 3.34.1\n",
            "pyngrok version 7.5.0\n"
          ]
        }
      ],
      "source": [
        "!ngrok version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pl1BWU_TRoO",
        "outputId": "ad809977-cbb5-4edb-d33c-1058ccae2a7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.52.2)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.5.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.4)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2.13.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.30.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit sentence-transformers scikit-learn pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNLJKjdDOB5-",
        "outputId": "e35451ad-1a18-43c0-fd60-dcc2830e2769"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fpdf in /usr/local/lib/python3.12/dist-packages (1.7.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install fpdf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPn2Xq2gglZL",
        "outputId": "1749cffd-8a10-43e0-aad5-f424cf1f1a36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.28.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.187.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.43.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.12.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (6.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "pip install google-generativeai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdD0dgMQtxLA",
        "outputId": "81d555e5-5c0a-41e5-cf86-1b13e60352f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import hashlib\n",
        "import os\n",
        "\n",
        "# OPTIONAL GEMINI (SAFE)\n",
        "\n",
        "USE_GEMINI = True\n",
        "try:\n",
        "    import google.generativeai as genai\n",
        "    genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
        "    gemini_model = genai.GenerativeModel(\"models/gemini-1.5-flash\")\n",
        "except:\n",
        "    USE_GEMINI = False\n",
        "\n",
        "def gemini_generate(prompt):\n",
        "    if not USE_GEMINI:\n",
        "        return None\n",
        "    try:\n",
        "        return gemini_model.generate_content(prompt).text\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# -----------------------------\n",
        "# CONFIG\n",
        "# -----------------------------\n",
        "st.set_page_config(page_title=\"AI Skill Gap & Assessment\", layout=\"wide\")\n",
        "\n",
        "# -----------------------------\n",
        "# SESSION STATE\n",
        "# -----------------------------\n",
        "for key, default in {\n",
        "    \"users\": {},\n",
        "    \"logged_in\": False,\n",
        "    \"username\": \"\",\n",
        "    \"mcq_submitted\": False,\n",
        "    \"aptitude_submitted\": False,\n",
        "    \"skill_gap_df\": pd.DataFrame(),\n",
        "    \"aptitude_score\": 0,\n",
        "    \"mcq_score\": 0\n",
        "}.items():\n",
        "    if key not in st.session_state:\n",
        "        st.session_state[key] = default\n",
        "\n",
        "# -----------------------------\n",
        "# UTILS\n",
        "# -----------------------------\n",
        "def hash_password(pw):\n",
        "    return hashlib.sha256(pw.encode()).hexdigest()\n",
        "\n",
        "# -----------------------------\n",
        "# AUTH PAGE\n",
        "# -----------------------------\n",
        "def auth_page():\n",
        "    st.title(\"🔐 Sign In\")\n",
        "\n",
        "    if not st.session_state.users:\n",
        "        st.subheader(\"🆕 Create Account (First time only)\")\n",
        "        su = st.text_input(\"New Username\")\n",
        "        sp = st.text_input(\"New Password\", type=\"password\")\n",
        "\n",
        "        if st.button(\"Sign Up\"):\n",
        "            if su and sp:\n",
        "                st.session_state.users[su] = hash_password(sp)\n",
        "                st.success(\"Account created. Login below.\")\n",
        "            else:\n",
        "                st.error(\"Fill all fields\")\n",
        "\n",
        "        st.divider()\n",
        "\n",
        "    st.subheader(\"🔑 Login\")\n",
        "    lu = st.text_input(\"Username\", key=\"lu\")\n",
        "    lp = st.text_input(\"Password\", type=\"password\", key=\"lp\")\n",
        "\n",
        "    if st.button(\"Login\"):\n",
        "        if lu in st.session_state.users and st.session_state.users[lu] == hash_password(lp):\n",
        "            st.session_state.logged_in = True\n",
        "            st.session_state.username = lu\n",
        "            st.rerun()\n",
        "        else:\n",
        "            st.error(\"Invalid credentials\")\n",
        "\n",
        "# -----------------------------\n",
        "# SKILL GAP\n",
        "# -----------------------------\n",
        "def skill_gap_page():\n",
        "    st.header(\"📊 Skill Gap Analysis\")\n",
        "\n",
        "    resume = st.file_uploader(\"Upload Resume CSV\", type=\"csv\")\n",
        "    internship = st.file_uploader(\"Upload Internship CSV\", type=\"csv\")\n",
        "\n",
        "    if resume is None or internship is None:\n",
        "        st.info(\"Upload BOTH files to view Skill Gap Report.\")\n",
        "        return\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        \"Name\": [\"Uma\", \"Anu\", \"Ram\", \"Sita\", \"Radha\"],\n",
        "        \"Skill Gap %\": [33, 0, 0, 33, 33]\n",
        "    })\n",
        "\n",
        "    st.session_state.skill_gap_df = df\n",
        "    st.dataframe(df)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(4,3))\n",
        "    ax.bar(df[\"Name\"], df[\"Skill Gap %\"])\n",
        "    ax.set_ylim(0, 100)\n",
        "    st.pyplot(fig)\n",
        "\n",
        "# -----------------------------\n",
        "# APTITUDE TEST (10 Q + SCORE)\n",
        "# -----------------------------\n",
        "def aptitude_test():\n",
        "    st.header(\"🧮 Aptitude Test\")\n",
        "\n",
        "    questions = [\n",
        "        (\"20% of 250?\", \"50\", [\"25\",\"40\",\"50\",\"60\"]),\n",
        "        (\"2^5?\", \"32\", [\"16\",\"32\",\"64\",\"25\"]),\n",
        "        (\"SI of 1000 @10% for 2 years?\", \"200\", [\"100\",\"200\",\"300\",\"400\"]),\n",
        "        (\"Speed = Distance / ?\", \"Time\", [\"Time\",\"Force\",\"Work\",\"Power\"]),\n",
        "        (\"5 × 12?\", \"60\", [\"50\",\"55\",\"60\",\"65\"]),\n",
        "        (\"Square root of 144?\", \"12\", [\"10\",\"11\",\"12\",\"13\"]),\n",
        "        (\"15% of 200?\", \"30\", [\"20\",\"25\",\"30\",\"35\"]),\n",
        "        (\"1000 / 10?\", \"100\", [\"10\",\"50\",\"100\",\"200\"]),\n",
        "        (\"3²?\", \"9\", [\"6\",\"9\",\"12\",\"15\"]),\n",
        "        (\"LCM of 2 and 4?\", \"4\", [\"2\",\"4\",\"6\",\"8\"])\n",
        "    ]\n",
        "\n",
        "    score = 0\n",
        "    for i, (q, ans, opts) in enumerate(questions):\n",
        "        user = st.radio(f\"{i+1}. {q}\", opts, index=None, key=f\"apt{i}\")\n",
        "        if user == ans:\n",
        "            score += 1\n",
        "\n",
        "    if st.button(\"Submit Aptitude Test\"):\n",
        "        st.session_state.aptitude_submitted = True\n",
        "        st.session_state.aptitude_score = score\n",
        "        st.success(f\"Your Aptitude Score: {score} / 10\")\n",
        "\n",
        "# -----------------------------\n",
        "# MCQ TEST (10 Q + SCORE)\n",
        "# -----------------------------\n",
        "def mcq_test():\n",
        "    st.header(\"💻 MCQ Test\")\n",
        "\n",
        "    questions = [\n",
        "        (\"Priority queue uses?\", \"Heap\", [\"Array\",\"Linked List\",\"Heap\",\"Stack\"]),\n",
        "        (\"[1,2,3]*2?\", \"[1,2,3,1,2,3]\", [\"[2,4,6]\",\"[1,2,3,1,2,3]\",\"Error\",\"None\"]),\n",
        "        (\"NOT OOP concept?\", \"Compilation\", [\"Inheritance\",\"Encapsulation\",\"Compilation\",\"Polymorphism\"]),\n",
        "        (\"Runs on JVM?\", \"Java\", [\"Python\",\"C\",\"Java\",\"JavaScript\"]),\n",
        "        (\"Keyword for inheritance?\", \"extends\", [\"this\",\"super\",\"extends\",\"implements\"]),\n",
        "        (\"Loop for known iterations?\", \"for\", [\"while\",\"do-while\",\"for\",\"switch\"]),\n",
        "        (\"SQL used for?\", \"Database\", [\"UI\",\"Database\",\"OS\",\"Network\"]),\n",
        "        (\"HTML stands for?\", \"HyperText Markup Language\",\n",
        "         [\"HighText ML\",\"HyperText Markup Language\",\"Hyper Tool ML\",\"None\"]),\n",
        "        (\"CSS used for?\", \"Styling\", [\"Logic\",\"Styling\",\"Database\",\"Server\"]),\n",
        "        (\"Python is?\", \"Interpreted\", [\"Compiled\",\"Interpreted\",\"Machine\",\"Assembly\"])\n",
        "    ]\n",
        "\n",
        "    score = 0\n",
        "    for i, (q, ans, opts) in enumerate(questions):\n",
        "        user = st.radio(f\"{i+1}. {q}\", opts, index=None, key=f\"mcq{i}\")\n",
        "        if user == ans:\n",
        "            score += 1\n",
        "\n",
        "    if st.button(\"Submit MCQ Test\"):\n",
        "        st.session_state.mcq_submitted = True\n",
        "        st.session_state.mcq_score = score\n",
        "        st.success(f\"Your MCQ Score: {score} / 10\")\n",
        "\n",
        "# -----------------------------\n",
        "# CAREER GUIDANCE\n",
        "# -----------------------------\n",
        "def career_guidance():\n",
        "    st.header(\"🧭 Career Guidance\")\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "## 🔥 Trending Skills\n",
        "- Artificial Intelligence\n",
        "- Data Science\n",
        "- Cloud Computing\n",
        "- Cybersecurity\n",
        "- Full Stack Development\n",
        "\n",
        "## 🚀 Trending Careers\n",
        "- AI Engineer\n",
        "- Data Analyst\n",
        "- Cloud Architect\n",
        "- Cybersecurity Analyst\n",
        "- Software Developer\n",
        "\"\"\")\n",
        "\n",
        "# -----------------------------\n",
        "# DASHBOARD\n",
        "# -----------------------------\n",
        "def dashboard():\n",
        "    st.header(\"📈 Dashboard\")\n",
        "\n",
        "    df = st.session_state.skill_gap_df\n",
        "    if not df.empty:\n",
        "        fig, ax = plt.subplots(figsize=(4,3))\n",
        "        ax.bar(df[\"Name\"], df[\"Skill Gap %\"])\n",
        "        ax.set_ylim(0, 100)\n",
        "        st.pyplot(fig)\n",
        "\n",
        "    fig2, ax2 = plt.subplots(figsize=(4,3))\n",
        "    ax2.bar(\n",
        "        [\"Aptitude\",\"MCQ\"],\n",
        "        [st.session_state.aptitude_score, st.session_state.mcq_score]\n",
        "    )\n",
        "    ax2.set_ylim(0, 10)\n",
        "    st.pyplot(fig2)\n",
        "\n",
        "# -----------------------------\n",
        "# MAIN\n",
        "# -----------------------------\n",
        "if not st.session_state.logged_in:\n",
        "    auth_page()\n",
        "else:\n",
        "    st.sidebar.success(f\"Logged in as {st.session_state.username}\")\n",
        "    page = st.sidebar.radio(\n",
        "        \"Navigation\",\n",
        "        [\"Skill Gap Analysis\",\"Aptitude Test\",\"MCQ Test\",\"Career Guidance\",\"Dashboard\",\"Logout\"]\n",
        "    )\n",
        "\n",
        "    if page == \"Skill Gap Analysis\":\n",
        "        skill_gap_page()\n",
        "    elif page == \"Aptitude Test\":\n",
        "        aptitude_test()\n",
        "    elif page == \"MCQ Test\":\n",
        "        mcq_test()\n",
        "    elif page == \"Career Guidance\":\n",
        "        career_guidance()\n",
        "    elif page == \"Dashboard\":\n",
        "        dashboard()\n",
        "    elif page == \"Logout\":\n",
        "        st.session_state.logged_in = False\n",
        "        st.rerun()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYyrxYpeP3lW",
        "outputId": "a7aeafd2-3806-4d4c-d6bb-6415b7e9dce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.126.80.35:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py --server.port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXJOaZO-b_XS"
      },
      "outputs": [],
      "source": [
        "!nohup streamlit run app.py --server.port 8501 > streamlit.log 2>&1 &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGDuGwpLQW3d",
        "outputId": "ea301b74-d399-4a4d-d5e3-edc1c32eca34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NgrokTunnel: \"https://nonjuristical-ema-polyangular.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ],
      "source": [
        "public_url = ngrok.connect(8501)\n",
        "print(public_url)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}